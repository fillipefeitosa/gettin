{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work structure\n",
    "Quero discutir duas questões fundamentais:\n",
    "\n",
    "1. O que é justiça social e como ela passa a ser justiça territorial (spatial justice)?\n",
    "2. Quais os pricipais principios de justiça?\n",
    "\n",
    "\n",
    "1. Como medir justiça espacial por meio da distância?\n",
    "2. Como mensurar a dificuldade de se chegar a uma oportunidade além das condições físicas de mobilidade (distância) e de acesso? (em outras palavras, o que caracteriza a diferença de acesso para diferentes grupos socio-economicos)\n",
    "\n",
    "Pensar nessas questões a partir de uma componente espacial de justiça (Fainstein, 2014) usando a distância como unidade de medida.\n",
    "\n",
    "\n",
    "Em seguida quero compreender a impedância como um fator que pode gerar diferentes interpretações do espaço urbano e usar essa métrica num lugar conhecido (Aveiro-Ílhavo). Depois de compreender que fatores socio-econômicos podem influenciar o \"ease of access\" às oportunidades, quero aplicar uma fórmula na impedância (distância) para calcular um indicador de \"acessibilidade social\"\n",
    "\n",
    "\n",
    "Justice is \n",
    "Ease of access\n",
    "the way access is measured is not satisfatory (why)\n",
    "qualidade não é um fator relevante para essa análise.\n",
    "\n",
    "---\n",
    "\n",
    "### To Do:\n",
    "\n",
    "- [ ] Discutir (1)\"medição de justiça espacial\" de forma mais direta para rawls e utilitarismo, com base na literatura\n",
    "- [ ] Identificar na literatura mais fatores socio-economicos que podem influenciar a impedância (2)\n",
    "- [ ] Criar funções de impedância\n",
    "- [X] Criar modelo para Aveiro/ílhavo e aplicar funções de impedância conhecidas [DONE]\n",
    "- [ ] Aplicar funções de impedância social para aveiro/ílhavo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Perspectiva de medição de justiça ou de bem-estar \n",
    "\n",
    "### Abordagem de capacidade (Sen, Nussbaum)\n",
    "Justiça é oferecer o mínimo de acesso às oportunidades (capacidades) que permitem ao indivíduo ter escolhas para viver a vida como deseja (functionings) e ter bem estar (de acordo com suas preferências(Pref))\n",
    "\n",
    "   * Existe uma discussão na literatura científica sobre a métrica de justiça baseada em oportunidades (capacidades) ou em resultados (functionings)\n",
    "   * A abordagem de capacidade não é um princípio de justiça completo (Nussbaum 2006: 71). Como mensurar a justiça depois que todos tiverem acesso básico às oportunidades?\n",
    "   * São usados indicadores composósitos de bem-estar ou de justiça, como o IDH que agrega diferentes grupos. Entretanto, a abordagem mais adequada sugere o maior nível de desagregamento possível, ao nível do indivíduo(Pref). Marc Fleurbacy sugere uma medida individualizada baseada em preferências para encontrar a **renda equivalente**: quanto de renda a pessoa estaria disposta a abrir mão para ter mais saúde ou mais tempo livre?\n",
    "   * Considerando o modelo gravitacional, acredito que a melhor abordagem é criar uma função baseada na impedância cumulativa considerando os 7 tópicos essenciais (públicos) que Nussbaum elicita.\n",
    "\n",
    "##### Capacidade vs Utilitarismo\n",
    "* Uma alternativa para as visões normativas que focam em exercícios hipotéticos de avaliação. Basicamente, o que é sugerido pelo utilitarismo para medição do bem estar (ou da justiça), que é focado exclusivamente na utilidade (Sen 1999: 59,62), ou seja estados mentais e sentimentos de \"felicidade\", ou \"contentamento\"\n",
    "* Também há problema para as coisas que ficam de fora desse tipo de avaliação. A informação de não utilidade excluída também deveria ser considerada, como as capacidades físicas, ou condições de saúde de nascença. \n",
    "* Princípios morais e sociais, também não são considerados pelo utilitarismo, como salários iguais para as mesmas funções. \n",
    "* Para o utilitarismo, homens devem ganhar mais enquanto as mulheres estiverem satisfeitas com o que ganham e a utilidade do sistema seja maximizada. \n",
    "\n",
    "\n",
    "##### Capacidade vs Rawls\n",
    "“the primary goods approach seems to take little note of the diversity of human beings. … If people were basically very similar, then an index of primary goods might be quite a good way of judging advantage. But, in fact, people seem to have very different needs varying with health, longevity, climatic conditions, location, work conditions, temperament, and even body size.    …    So what is being involved is not merely ignoring a few hard cases, but overlooking very widespread and real differences” \n",
    "(Sen 1980: 215–216)\n",
    "\n",
    "* Autores da abordagem de capacidade acreditam que o problema geral de medir a justiça a partir dos \"bens primários\" (rawls primary goods) é que eles não lidam de forma adequada com a diversidade humana, já que não foca em resultados mas sim nos meios (greatest equal liberty principle), e portanto deixa alguns grupos de fora do escopo da justiça.\n",
    "\n",
    "\n",
    "### Teoria de Justiça \"Rawlsiana\" (Rawls, Fainstein)\n",
    "Justiça é distribuir recursos e serviços desigualmente de forma a fornecer o melhor benefício possível para os menos favorecidos (Rawls, 1999). [Difference Principle]\n",
    "\n",
    "Justiça também é fornecer igual acesso a recursos básicos, bens, renda e riqueza, oportunidades e **liberdades** (Rawls, 1971) [greatest equal liberty principle]\n",
    "\n",
    "\n",
    "\n",
    "### Utilitarismo\n",
    "Justiça é maximizar o nível de satisfação do sistema, ou seja, distriuir o recurso de tal forma que o valor total de satisfação do sistema seja o maior possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Distância e grupo social -> Impedância social\n",
    "\n",
    "Quanto maior a disância e menor o grupo social, mais difícil é o acesso à oportunidade. O problema é:\n",
    "\n",
    "* O quão mais difícil é para cada grupo, e por que?\n",
    "* Quais são as características socio-econômicas de cada grupo que justificam a facilidade (ou dificuldade) de acesso? (ie. possui carro, tem acesso a parada de autocarro nas redondezas)\n",
    "    * Necessidade de ter duas medidas: uma para as oportunidades (modelo gravitacional) e outra para a mobilidade (o tipo de facilidade que o indivíduo tem para acessar as facilidades\n",
    "    * Comparar medidas com a média (para se adequar a uma norma). Inclusive SE eu for trabalhar com preferências individuais (ie. Mapa de classificação com os valores que mais se aproximam ou se distanciam da média)\n",
    "    \n",
    "    \n",
    "#### Quais fatores socio-economicos auxiliam/prejudicam o acesso (ou o que sei até agora)\n",
    "\n",
    "\n",
    "\n",
    "which justifies the construction of local indexes (Arellana et al., 2020)\n",
    "\n",
    "individual socioeconomic factors and their perceptions on the conditions of the infrastructure and the built environment strongly impact the decision to travel by active modes (Larrañaga et al., 2016, Arellana et al., 2020).\n",
    "\n",
    "People from higher social classes tends to commute with car:\n",
    "the socioeconomic level, 82.4% of respondents belonged to strata 1 and 2, 16.2% to strata 3 and 4, and 1.4% to strata 5 and 6. This socioeconomic distribution suggests that most of the bicycle users in the city are low-income people.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Impedance Experiments\n",
    "Objective: Test different impedance functions \n",
    "\n",
    "Based on paper\n",
    "\n",
    "\n",
    "Vale, D. S., Saraiva, M., & Pereira, M. (2016). Active accessibility: A review of operational measures of walking and cycling accessibility. Journal of Transport and Land Use. University of Minnesota. https://doi.org/10.5198/jtlu.2015.593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandana as pdna\n",
    "import geopandas as gpd\n",
    "from pandana.loaders import osm\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_X_Y(points_dataframe):\n",
    "    \"\"\" Returns a geodataframe with lat and long decomposed from \n",
    "    geometry on given dataframe\n",
    "    Creteas two Series (lat and long) and alocate them on nodeX and nodeY \"\"\"\n",
    "    nodesX = []\n",
    "    nodesY = []\n",
    "    for e in points_dataframe[['geometry']].iterrows():\n",
    "        nodesX.append(e[1].geometry.x)\n",
    "        nodesY.append(e[1].geometry.y)\n",
    "    points_dataframe['nodeX'] = nodesX\n",
    "    points_dataframe['nodeY'] = nodesY\n",
    "    return points_dataframe\n",
    "\n",
    "def select_accessibility(regionName):\n",
    "    accessibility_selection = pd.read_csv('data/accessibility/'+regionName+'/accessibilityMean.csv', dtype={'key_0':str})\n",
    "    accessibility_selection['key_0'] = accessibility_selection['key_0'].apply(lambda x: str(x).zfill(11))\n",
    "    accessibility_selection = clean_accessibility_df(accessibility_selection)\n",
    "    return accessibility_selection\n",
    "\n",
    "def clean_accessibility_df(access_df):\n",
    "    access_df = access_df.rename(columns={'key_0':\"BGRI\",'1':'accessN1', '2':'accessN2', '3':'accessN3'})\n",
    "    access_df = access_df.drop(columns=['Unnamed: 0'])\n",
    "    return access_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "../data/BGRI_2011/CONTINENTE/BGRI11_CONT.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ../data/BGRI_2011/CONTINENTE/BGRI11_CONT.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-797fdd901326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load Polygon data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mportugal_polygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/BGRI_2011/CONTINENTE/BGRI11_CONT.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/pandana/lib/python3.6/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, bbox, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pandana/lib/python3.6/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pandana/lib/python3.6/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0;32m--> 253\u001b[0;31m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pandana/lib/python3.6/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: ../data/BGRI_2011/CONTINENTE/BGRI11_CONT.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Load Polygon data\n",
    "portugal_polygon = gpd.read_file('../data/BGRI_2011/CONTINENTE/BGRI11_CONT.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Qualification Indexes\n",
    "portugal_qi = pd.read_excel('../data/qi_portugal.xlsx', dtype={'BGRI11': str, 'IQ':float} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Schools Data\n",
    "schools = gpd.read_file('../data/escolas_portugal_corrigido/gdf_escolas_publicas_1CEB.shx')\n",
    "schools = schools.to_crs({'init':'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Aveiro(0105) and Ílhavo(0110) cities From Continental Portugal\n",
    "aveiro_ilhavo_polygon = portugal_polygon[(portugal_polygon['DTMN11']=='0105') | (portugal_polygon['DTMN11']=='0110')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust projection to wgs-84 and get subsection centroids\n",
    "aveiro_ilhavo_polygon = aveiro_ilhavo_polygon.to_crs({'init': 'epsg:4326'})\n",
    "aveiro_ilhavo_polygon['temp'] = 1\n",
    "aveiro_ilhavo_shape = aveiro_ilhavo_polygon.dissolve(by='temp')\n",
    "aveiro_ilhavo_centroids = aveiro_ilhavo_polygon.centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the schools that are inside Aveiro_Ilhavo Region\n",
    "aveiro_ilhavo_schools = gpd.sjoin(schools[['ESCOLA','CÓD. DGPGF','geometry']],aveiro_ilhavo_shape[['geometry']],how='inner', op='intersects')\n",
    "aveiro_ilhavo_schools = get_point_X_Y(aveiro_ilhavo_schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Polygon Bounds\n",
    "bounds = aveiro_ilhavo_polygon.total_bounds\n",
    "bbox = [bounds[1], bounds[0], bounds[3], bounds[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pandana Network\n",
    "network = osm.pdna_network_from_bbox(*bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create POIS and precompute\n",
    "maxDistance = 10000\n",
    "maxItems = 5\n",
    "network.set_pois('schools', maxDistance, maxItems, aveiro_ilhavo_schools['nodeX'],aveiro_ilhavo_schools['nodeY'])\n",
    "network.precompute(maxDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the accessibility\n",
    "accessibility = network.nearest_pois(1000, 'schools', num_pois=3, imp_name='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impedance class definition\n",
    "Used to apply different impedance functions on the accessibily dataframe\n",
    "\n",
    "According to Vale (Vale et al., 2016) \n",
    "\n",
    "\" ... gravity-based measures explicitly assume attenuation toward travel. Three functions are often used: inverse power, negative exponential, and modified Gaussian\"\n",
    "\n",
    "Parameters were established by analyzing the changes in the rate of decline and the point at which the function approaches zero (Figure 3). Specifically, we established different values (0.50, 0.25, 0.125, 0.062, and 0.031) of the function at different distances from origins. Fifty meters from the origin was chosen for power functions due to the high elasticity of the function near the origin, whereas for exponential measures we used 200 m. The parameters for Gaussian measures were established by setting the distance at which the function would take the value 0.50. The thresholds used for cumulative measures were based on the quarter-mile (400 m) rule of thumb, extended by intervals of 200 m. Finally, the cumulative–Gaussian parameters were chosen with two different criteria. CuGa1 and CuGa2 assume a 200m indifference travel distance and differ by altering the parameter of the Gaussian part. CuGa3 and CuGa4 assume a 400m indifference travel distance and also differ by altering the Gaussian part of the function.\n",
    "\n",
    "Parameter a reflects\n",
    "the acceptable pedestrian distance and parameter v reflects the slope of the curve after that initial distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Impedance:\n",
    "    \n",
    "    def __init__(self, accessibility_dataframe):\n",
    "        self.df = accessibility_dataframe\n",
    "    \n",
    "    def apply_impedance_functions(self, n=1):\n",
    "        self.cumulative(n)\n",
    "        self.inverse_power(n)\n",
    "        self.negative_exponential(n)\n",
    "        self.modified_gaussian(n)\n",
    "        self.cumulative_gaussian(n)\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def cumulative(self, n=1, alpha=400):\n",
    "        self.df['cumulative'] = self.df[n].apply(lambda x: 1 if x <= alpha else 0)\n",
    "            \n",
    "    def change_zeros(self, n=1, value=1):\n",
    "        self.df['non_zeros'] = self.df[n].apply(lambda x: value if x==0 else x)\n",
    "    \n",
    "    def inverse_power(self, n=1, alpha=0.709):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['inverse_power'] = self.df['non_zeros'].apply(lambda x: x**(-alpha))\n",
    "            \n",
    "    def negative_exponential(self, n=1, beta=0.003):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['negative_exponential'] = self.df['non_zeros'].apply(lambda x: np.exp(-beta*x))\n",
    "    \n",
    "    def modified_gaussian(self, n=1, slope=57708):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['modified_gaussian'] = self.df['non_zeros'].apply(lambda x: np.exp(-(x**2)/slope))\n",
    "        \n",
    "    def cumulative_gaussian(self, n=1, alpha=400, slope=57708):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['cumulative_gaussian'] = self.df['non_zeros'].apply(lambda x: 1 if x<=alpha else np.exp(- ((x-alpha)**2 )/slope ) )\n",
    "    \n",
    "    def group0_impedance(self):\n",
    "        self.change_zeros(n=n)\n",
    "#         self.df['accessibility_group0'] = self.df['non_zeros'].apply(lambda x: 1 if (x<=400 and  elif  np.exp(- ((x-400)**2 )/57708 ) )\n",
    "        \n",
    "    def group1_impedance(self):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['accessibility_group1'] = self.df['non_zeros'].apply(lambda x: 1 if x<=400 else np.exp(- ((x-400)**2 )/129843 ) )\n",
    "    \n",
    "    def group2_impedance(self):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['accessibility_group2'] = self.df['non_zeros'].apply(lambda x: 1 if x<=200 else np.exp(- ((x-200)**2 )/57708 ) )\n",
    "\n",
    "    def group3_impedance(self):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['accessibility_group3'] = self.df['non_zeros'].apply(lambda x: 1 if x<=200 else np.exp(- ((x-200)**2 )/(129843*8) ) )\n",
    "    \n",
    "    def group4_impedance(self):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['accessibility_group4'] = self.df['non_zeros'].apply(lambda x: 1 if x<=200 else np.exp(- ((x-200)**2 )/(129843*8) ) )\n",
    "        \n",
    "    def group5_impedance(self):\n",
    "        self.change_zeros(n=n)\n",
    "        self.df['accessibility_group5'] = self.df['non_zeros'].apply(lambda x: 1 if x<=50 else np.exp(- ((x-50)**2 )/(129843*30) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Impedance functions\n",
    "result = Impedance(accessibility)\n",
    "impedance = result.apply_impedance_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the plot directly via matplotlib\n",
    "def plot_functions(impedance_df, impedance_function=1):\n",
    "    fig, ax = plt.subplots(figsize=(15,11))\n",
    "    aveiro_ilhavo_shape.plot(ax=ax, facecolor='#DCDCDC', edgecolor='#B0C4DE')\n",
    "\n",
    "    plt.title('Aveiro-Ílhavo: Nearest Schools - {}'.format(impedance_function))\n",
    "    plt.scatter(network.nodes_df.x, network.nodes_df.y, \n",
    "                c=impedance_df[impedance_function], s=1, cmap='hot_r' \n",
    "                )\n",
    "    cb = plt.colorbar()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_functions(impedance, 1)\n",
    "plot_functions(impedance, 'cumulative')\n",
    "plot_functions(impedance, 'inverse_power')\n",
    "plot_functions(impedance, 'negative_exponential')\n",
    "plot_functions(impedance, 'modified_gaussian')\n",
    "plot_functions(impedance, 'cumulative_gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Accessibility Data based on region\n",
    "aveiro_accessibility = select_accessibility('AVEIRO')\n",
    "ilhavo_accessibility = select_accessibility('ÍLHAVO')\n",
    "aveiro_ilhavo_accessibility = pd.concat([aveiro_accessibility,ilhavo_accessibility])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Polygons with IQ and AccessN1 data\n",
    "aveiro_ilhavo_polygon = aveiro_ilhavo_polygon.merge(aveiro_ilhavo_accessibility[['BGRI', 'IQ','accessN1']], how='left', left_on='BGRI11', right_on='BGRI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only missing subsection points\n",
    "aveiro_ilhavo_missing = aveiro_ilhavo_polygon[aveiro_ilhavo_polygon.accessN1.isna()]\n",
    "aveiro_ilhavo_missing['geometry'] = aveiro_ilhavo_missing.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix missings and get IQ from raw base\n",
    "aveiro_ilhavo_missing = aveiro_ilhavo_missing.drop(columns=['BGRI', 'IQ', 'accessN1'])\n",
    "aveiro_ilhavo_missing = aveiro_ilhavo_missing.merge(portugal_qi, how='left', left_on='BGRI11', right_on='BGRI11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find distance lenght for the missing subsections\n",
    "aveiro_ilhavo_missing = get_point_X_Y(aveiro_ilhavo_missing)\n",
    "centroid_nodes = network.get_node_ids(aveiro_ilhavo_missing.nodeX, aveiro_ilhavo_missing.nodeY).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distances from the accessibility dataframe (using nearest nodes)\n",
    "missing_distances = []\n",
    "for missing in centroid_nodes:\n",
    "    distance = accessibility[accessibility.index==missing].iloc[0][1]\n",
    "    missing_distances.append(distance)\n",
    "aveiro_ilhavo_missing['accessN1'] = missing_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change index to allow distances and IQ allocation\n",
    "aveiro_ilhavo_polygon.index=aveiro_ilhavo_polygon.BGRI11\n",
    "aveiro_ilhavo_missing.index=aveiro_ilhavo_missing.BGRI11\n",
    "\n",
    "# Index and allocate respective values on original dataframe\n",
    "aveiro_ilhavo_polygon.loc[aveiro_ilhavo_polygon.accessN1.isna(), 'accessN1'] = aveiro_ilhavo_missing.loc[:,'accessN1']\n",
    "aveiro_ilhavo_polygon.loc[aveiro_ilhavo_polygon.IQ.isna(), 'IQ'] = aveiro_ilhavo_missing.loc[:,'IQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aveiro_ilhavo_polygon.plot(column='accessN1', cmap='Blues_r', figsize=(15,15), k=8, scheme='equal_interval', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aveiro_ilhavo_polygon.plot(column='IQ', cmap='Blues', figsize=(15,15), k=8, scheme='equal_interval', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"less than 1 year\", \"1 to 4 years\", \"4 to 6 years\", \"6 to 8 years\", \"8 to 12 years\", \"12 or more\"]\n",
    "bins = pd.IntervalIndex.from_tuples([(-1, 1), (1, 4), (4, 6),(6,8),(8,12),(12,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1,1,4,6,8,12,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aveiro_ilhavo_polygon['group'] = pd.cut(aveiro_ilhavo_polygon.IQ,bins,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aveiro_ilhavo_polygon.plot(column='group', categorical=True, cmap='GnBu', figsize=(15,15), legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aveiro_ilhavo_polygon[['accessN1','IQ']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aveiro_ilhavo_polygon.to_excel('./data/impedanceWithIQ.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get different amenities to include in calculation\n",
    "aveiro_ilhavo_pois = pd.read_csv('./data/pois/aveiro-ilhavo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in aveiro_ilhavo_pois.columns:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = aveiro_ilhavo_pois[['id','lat','lon','leisure','access','office', 'amenity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pois[pois['amenity'].notna()].amenity.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorias para experimento com Impedância\n",
    "\n",
    "* Serviços Básicos\n",
    "\n",
    " * educação: school (primárias retiradas da fonte oficial)\n",
    "\n",
    " * saúde: clinic,doctors\n",
    "\n",
    "* Área Verde:\n",
    "park, garden\n",
    "\n",
    "* Amenidades:\n",
    "cafe, pub, restaurant\n",
    "\n",
    "* Culturais:\n",
    "theatre, library, cinema\n",
    "\n",
    "* Conveniência: \n",
    "atm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subsets for each amenity\n",
    "pois_health = pois[(pois['amenity']=='clinic') | (pois['amenity']=='doctors')]\n",
    "pois_green = pois[(pois['leisure']=='garden') | (pois['leisure']=='park')]\n",
    "pois_amenities = pois[(pois['amenity']=='cafe') | (pois['amenity']=='pub') | (pois['amenity']=='restaurant')]\n",
    "pois_cultural = pois[(pois['amenity']=='theatre') | (pois['amenity']=='library') | (pois['amenity']=='cinema')]\n",
    "pois_convenience = pois[pois['amenity']=='atm']\n",
    "\n",
    "# Propose an arbitrary attractiveness factor (not based on justice)\n",
    "# já podem existir nessas preferências indicações socio-economicas\n",
    "# de o indivíduo efetivamente possa fazer usurfruto dessas amenidades (utilidade/functionings) \n",
    "# uma questão interessante: por que as classes sociais mais baixas não consideram que precisam ou não tirar proveito de certas amenidades, como culturais\n",
    "pois_health['attractiveness'] = 0.7\n",
    "pois_green['attractiveness'] = 0.6\n",
    "pois_amenities['attractiveness'] = 1\n",
    "pois_cultural['attractiveness'] = 0.8\n",
    "pois_convenience['attractiveness'] = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Schools to the party\n",
    "aveiro_ilhavo_to_pois_all = aveiro_ilhavo_schools.rename(columns={'nodeX':'lon','nodeY':'lat'})\n",
    "aveiro_ilhavo_to_pois_all['amenity'] = 'primary_school'\n",
    "aveiro_ilhavo_to_pois_all['attractiveness'] = 0.9\n",
    "aveiro_ilhavo_to_pois_all = aveiro_ilhavo_to_pois_all[['lat','lon','amenity','attractiveness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a One to rule them All dataframe \n",
    "pois_all = [pois_health, pois_green, pois_amenities, pois_cultural, pois_convenience,aveiro_ilhavo_to_pois_all]\n",
    "pois_all = pd.concat(pois_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pois[pois['leisure'].notna()].leisure.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pois[pois['office'].notna()].office.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good way to separate for different amenities is to\n",
    "# network_all_pois = pdna.network.Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances for all pois\n",
    "x, y = pois_all['lon'], pois_all['lat']\n",
    "network.set_pois('all_pois',1000,10,x,y)\n",
    "network.precompute(2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculte distances\n",
    "# accessibility = network.nearest_pois(1000, 'schools', num_pois=3, imp_name='distance')\n",
    "accessibility_all = network.nearest_pois(1000,'all_pois',num_pois=3,imp_name='distance',include_poi_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Impedance functions\n",
    "result = Impedance(accessibility_all)\n",
    "impedance = result.apply_impedance_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_functions(impedance, 1)\n",
    "plot_functions(impedance, 3)\n",
    "# plot_functions(impedance, 5)\n",
    "# plot_functions(impedance, 10)\n",
    "# plot_functions(impedance, 'cumulative')\n",
    "# plot_functions(impedance, 'inverse_power')\n",
    "# plot_functions(impedance, 'negative_exponential')\n",
    "plot_functions(impedance, 'modified_gaussian')\n",
    "plot_functions(impedance, 'cumulative_gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impedance.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3 = Impedance(accessibility_all)\n",
    "impedance_3 = result.apply_impedance_functions(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_functions(impedance_3, 'modified_gaussian')\n",
    "plot_functions(impedance_3, 'cumulative_gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all POIS_IDS int32\n",
    "accessibility_all.loc[(accessibility_all['poi1'].notna()), 'poi1'] = accessibility_all.loc[(accessibility_all['poi1'].notna()), 'poi1'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessibility_all.astype({'poi1':'int32','poi2':'int32','poi3':'int32'}).dtypes\n",
    "# accessibility_all.loc[(true_test), ['poi1' ,'poi2','poi3']]\n",
    "# df.astype({'col1': 'int32'}).dtypes\n",
    "accessibility_all.loc[(accessibility_all['poi1'].notna()), 'poi1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
